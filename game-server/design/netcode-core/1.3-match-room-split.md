# Match/Room 분리 & Redis 세션/복구 설계 일지 (v1.3)
> 매치메이킹과 게임 룸을 분리하고, Redis 기반 세션 관리 및 재접속 지원

## 1. 문제 정의 & 요구사항

### 1.1 v1.0-1.2의 한계

**현재 아키텍처 (단일 서버):**
```text
[클라이언트] --UDP--> [pong_udp 서버] (매치메이킹 + 게임 + 세션 모두 처리)
```

**문제점:**

1. **확장성 제약**
   - 하나의 프로세스에서 모든 룸 처리 → CPU 병목
   - 동시 룸 수 증가 시 틱 레이트 저하
   - 수평 확장 불가 (서버 추가해도 부하 분산 안 됨)

2. **매치메이킹 복잡도**
   - MMR 기반 매칭을 인메모리로만 처리 → 재시작 시 큐 손실
   - 여러 룸 서버 간 매칭 불가

3. **세션 영속성 부족**
   - 클라이언트 재접속 시 상태 복구 어려움
   - 서버 재시작 시 모든 세션 소실

4. **장애 격리 불가**
   - 게임 로직 버그가 매치메이커까지 영향
   - 한 룸 서버 장애 시 전체 시스템 다운

### 1.2 목표

#### 1.2.1 Match/Room 분리 아키텍처

```text
[클라이언트]
    |
    v
[Matcher 서비스]  <--> [Redis] (큐, 룸 맵, 세션)
    |                     ^
    | (룸 배정)            |
    v                     |
[pong_udp 인스턴스 N개] --+
```

**역할 분담:**
- **Matcher**: 매치메이킹, 세션 검증, 룸 배정
- **pong_udp (Room Server)**: 게임 루프, 상태 동기화만 담당
- **Redis**: 공유 상태 저장 (큐, 세션, 체크포인트)

#### 1.2.2 Redis 기반 세션 관리

**핵심 기능:**
1. **세션 토큰**: 클라이언트 인증 및 player_id 매핑
2. **룸 매핑**: player_id → room_id, room_addr 저장
3. **체크포인트**: 룸별 최신 스냅샷 저장 (재접속용)
4. **매치 큐**: MMR 기반 ZSET으로 대기열 관리

#### 1.2.3 재접속 (Reconnection) 지원

**시나리오:**
1. 클라이언트 네트워크 끊김
2. 3초 이내 재접속 시도
3. Matcher가 기존 player_id 확인 → 같은 룸으로 리디렉션
4. Room Server가 체크포인트로 상태 복구 → 게임 계속 진행

**목표:**
- 재접속 성공률 > 95% (3초 이내)
- 체크포인트 복구 지연 < 1초
- 세션 손실 0% (Redis 영속성 보장)

### 1.3 비기능 요구사항

#### 1.3.1 확장성
- 50 동시 룸에서 60 TPS 유지 (룸당 2명 = 100 플레이어)
- Matcher 처리량 > 100 req/s (매칭 요청)

#### 1.3.2 고가용성
- Matcher 장애 시 Room Server는 계속 동작 (기존 게임 영향 없음)
- Redis 장애 시 503 + 백오프, 복구 시 자연스러운 회복

#### 1.3.3 일관성
- player_id → room_id 매핑 정확성 100%
- 중복 매칭 방지 (한 플레이어가 여러 룸에 배정되지 않도록)

---

## 2. 기술적 배경 & 설계 동기

### 2.1 왜 Match/Room을 분리하는가?

**모놀리식 서버 (v1.0-1.2):**
```cpp
class PongServer {
    GameLoop game_loop_;
    std::vector<Room> rooms_;
    MatchQueue match_queue_;
    SessionManager sessions_;
};
```

**문제:**
- `GameLoop::tick()`이 모든 룸을 순회 → O(N) 복잡도
- N=50 룸이면 틱당 시간 예산 부족
- CPU 코어 1개만 사용 (게임 루프는 단일 스레드)

**분리 아키텍처:**
```text
Matcher (별도 프로세스)
  - 매치메이킹만 담당
  - HTTP/gRPC API
  - 상태 저장 없음 (Redis에 위임)

pong_udp Instance 1 (Room 1~25)
pong_udp Instance 2 (Room 26~50)
  - 각각 독립적인 GameLoop
  - CPU 코어별로 분산 가능
```

**장점:**
- 수평 확장: 서버 추가 → 룸 증가
- 장애 격리: 한 인스턴스 다운 → 나머지는 정상
- 리소스 최적화: 매칭은 CPU 적게, 게임은 많이 사용

### 2.2 왜 Redis인가?

**대안 비교:**
| 저장소 | 장점 | 단점 |
|--------|------|------|
| **Redis** | 빠름(< 1ms), ZSET 지원, 간단한 설정 | 메모리 기반, 영속성 선택적 |
| PostgreSQL | 영속성 강함, ACID 보장 | 지연 높음(~10ms), 실시간 부적합 |
| Memcached | 매우 빠름 | 자료구조 제한 (ZSET 없음) |
| etcd | 분산 일관성, 강한 보장 | 오버킬 (게임에 불필요한 기능 많음) |

**선택 이유:**
- **ZSET (Sorted Set)**: MMR을 score로, player_id를 member로 → 매칭 쿼리 O(log N)
- **TTL 지원**: 세션/체크포인트 자동 만료
- **Pub/Sub**: 향후 실시간 이벤트 브로드캐스트 가능 (v1.4+)
- **Redis 영속성**: AOF/RDB로 재시작 후에도 세션 보존

### 2.3 재접속 vs 새 접속

**전통적 방식 (새 접속):**
- 재접속 시 새 player_id 발급 → 기존 게임 참여 불가
- 상대방은 "opponent disconnected" 메시지 후 게임 종료

**재접속 지원:**
- player_id 유지 → Redis에서 기존 룸 조회
- Room Server가 체크포인트로 상태 복구
- 상대방은 "opponent reconnected" 알림만 받음

**트레이드오프:**
- 복잡도 증가 (세션/체크포인트 관리)
- 메모리 오버헤드 (체크포인트 저장)
- 하지만 **사용자 경험 대폭 개선**

---

## 3. Redis 데이터 모델

### 3.1 핵심 키 구조

#### `match:queue` (ZSET)
- **용도**: 매칭 대기 큐
- **score**: MMR (Matchmaking Rating)
- **member**: player_id
- **예시**:
  ```
  ZADD match:queue 1200 "player123"
  ZADD match:queue 1250 "player456"
  ZRANGE match:queue 0 -1 WITHSCORES
  -> ["player123", 1200, "player456", 1250]
  ```

#### `session:{token}` (Hash)
- **용도**: 세션 토큰 → player_id 매핑
- **TTL**: 86400초 (24시간)
- **필드**:
  ```
  HSET session:abc123 player_id "player123"
  HSET session:abc123 expires "1700000000"
  EXPIRE session:abc123 86400
  ```

#### `room_map:{player_id}` (Hash)
- **용도**: 플레이어가 배정된 룸 정보
- **TTL**: 300초 (5분, 게임 종료 시 수동 삭제)
- **필드**:
  ```
  HSET room_map:player123 room_id "room001"
  HSET room_map:player123 addr "127.0.0.1:7777"
  EXPIRE room_map:player123 300
  ```

#### `room:{id}:checkpoint` (String, binary)
- **용도**: 룸별 최신 스냅샷 (재접속용)
- **TTL**: 30초 (주기적으로 갱신)
- **값**: protobuf 직렬화 WorldState
- **예시**:
  ```
  SET room:room001:checkpoint <binary_snapshot>
  EXPIRE room:room001:checkpoint 30
  ```

#### `room:{id}:info` (Hash)
- **용도**: 룸 메타데이터 (player_count, status 등)
- **필드**:
  ```
  HSET room:room001:info player_count 2
  HSET room:room001:info status "active"
  HSET room:room001:info addr "127.0.0.1:7777"
  ```

### 3.2 키 명명 규칙

- **네임스페이스**: `match:`, `session:`, `room:`, `room_map:` 접두사
- **구분자**: `:` (Redis 권장)
- **복수형**: `rooms:list`, `players:active` 같은 집합은 복수형

---

## 4. Matchmaker 서비스 설계

### 4.1 클래스 구조

```cpp
namespace mini {

class Matchmaker {
public:
    explicit Matchmaker(const std::string& redis_host = "127.0.0.1",
                       int redis_port = 6379);
    ~Matchmaker();

    // 매치 큐 관리
    bool enqueue(const std::string& player_id, int mmr);
    bool dequeue(const std::string& player_id);
    std::vector<RoomAssignment> process_queue();
    size_t queue_size() const;

    // 룸 배정 저장/조회
    bool store_room_assignment(const std::string& player_id,
                              const std::string& room_id,
                              const std::string& addr,
                              int ttl_seconds = 300);
    std::optional<RoomAssignment> get_room_assignment(const std::string& player_id) const;

private:
    class Impl;  // hiredis 연결 캡슐화
    std::unique_ptr<Impl> impl_;

    static constexpr int MMR_TOLERANCE = 200;
};

struct RoomAssignment {
    std::string room_id;
    std::string addr;
    std::string player_id;
    std::string opponent_id;
};

} // namespace mini
```

### 4.2 매칭 알고리즘

**간단한 MMR 기반 매칭:**
```cpp
std::vector<RoomAssignment> Matchmaker::process_queue() {
    std::vector<RoomAssignment> assignments;

    // 1. 큐에서 모든 플레이어 가져오기 (MMR 순)
    std::vector<MatchRequest> queue;
    // ZRANGE match:queue 0 -1 WITHSCORES
    for (auto& req : redis_zrange_with_scores("match:queue")) {
        queue.push_back({req.member, static_cast<int>(req.score), time(nullptr)});
    }

    if (queue.size() < 2) return assignments;

    // 2. 슬라이딩 윈도우로 페어링
    for (size_t i = 0; i + 1 < queue.size(); i += 2) {
        auto& p1 = queue[i];
        auto& p2 = queue[i + 1];

        // MMR 차이 체크
        if (std::abs(p1.mmr - p2.mmr) > MMR_TOLERANCE) {
            continue;  // 다음 조합 시도
        }

        // 3. 룸 생성
        std::string room_id = generate_room_id();
        std::string addr = get_available_room_server();  // 부하 분산

        RoomAssignment assignment;
        assignment.room_id = room_id;
        assignment.addr = addr;
        assignment.player_id = p1.player_id;
        assignment.opponent_id = p2.player_id;
        assignments.push_back(assignment);

        // 4. Redis에 룸 매핑 저장
        store_room_assignment(p1.player_id, room_id, addr);
        store_room_assignment(p2.player_id, room_id, addr);

        // 5. 큐에서 제거
        redis_zrem("match:queue", p1.player_id);
        redis_zrem("match:queue", p2.player_id);
    }

    return assignments;
}
```

### 4.3 HTTP API (간단한 예시)

**엔드포인트:**
- `POST /match/enqueue` - 매치 큐에 추가
- `POST /match/dequeue` - 매치 큐에서 제거
- `GET /match/status` - 현재 배정된 룸 조회

**예시 (Boost.Beast):**
```cpp
void handle_enqueue(http::request<http::string_body> req,
                   http::response<http::string_body>& res) {
    auto j = json::parse(req.body());
    std::string player_id = j["player_id"];
    int mmr = j["mmr"];

    if (matchmaker_.enqueue(player_id, mmr)) {
        res.result(http::status::ok);
        res.body() = R"({"status":"queued"})";
    } else {
        res.result(http::status::internal_server_error);
    }
}
```

---

## 5. RoomManager 서비스

### 5.1 클래스 구조

```cpp
class RoomManager {
public:
    explicit RoomManager(const std::string& redis_host = "127.0.0.1",
                        int redis_port = 6379);
    ~RoomManager();

    // 룸 서버 등록 (헬스체크 TTL)
    bool register_room(const std::string& room_id,
                      const std::string& addr,
                      int max_players = 2,
                      int ttl_seconds = 60);

    bool update_room_players(const std::string& room_id, int player_count);
    std::optional<RoomInfo> get_available_room() const;
    std::optional<RoomInfo> get_room(const std::string& room_id) const;

    // 세션 관리
    bool create_session(const std::string& player_id,
                       const std::string& token,
                       int ttl_seconds = 86400);
    std::optional<SessionInfo> get_session(const std::string& token) const;
    bool delete_session(const std::string& token);

    // 체크포인트 (재접속용)
    bool store_checkpoint(const std::string& room_id,
                         const std::vector<uint8_t>& snapshot,
                         int ttl_seconds = 30);
    std::optional<std::vector<uint8_t>> get_checkpoint(const std::string& room_id) const;

private:
    class Impl;
    std::unique_ptr<Impl> impl_;
};
```

### 5.2 체크포인트 저장 (Room Server에서 호출)

```cpp
void PongUdpServer::tick() {
    // 게임 로직 업데이트
    auto state = world_.step(dt);

    // 5 틱마다 체크포인트 저장 (0.083초 주기)
    if (state.tick % 5 == 0) {
        auto snapshot = serialize_state(state);
        room_manager_.store_checkpoint(room_id_, snapshot, 30);
    }

    // 상태 브로드캐스트 ...
}
```

### 5.3 재접속 처리 (Room Server)

```cpp
void PongUdpServer::on_client_connect(const std::string& player_id) {
    // 1. Redis에서 기존 룸 조회
    auto assignment = matchmaker_.get_room_assignment(player_id);

    if (assignment && assignment->room_id == room_id_) {
        // 재접속!
        std::cout << "Player " << player_id << " reconnected\n";

        // 2. 체크포인트 복구 (있으면)
        auto checkpoint = room_manager_.get_checkpoint(room_id_);
        if (checkpoint) {
            auto state = deserialize_state(*checkpoint);
            world_.restore(state);
            std::cout << "Restored checkpoint at tick " << state.tick << "\n";
        }

        // 3. 플레이어 상태 "active"로 변경
        player_slots_[player_id].status = PlayerStatus::Active;
        broadcast_roles();  // 다른 플레이어에게 알림
    } else {
        // 새 접속
        // ... 정상 매칭 흐름
    }
}
```

---

## 6. 전체 흐름 시나리오

### 6.1 신규 매칭 + 게임 시작

```text
[클라이언트 A]
    |
    | POST /match/enqueue {"player_id":"A", "mmr":1200}
    v
[Matcher]
    | ZADD match:queue 1200 "A"
    | ... 대기 ...
    |
[클라이언트 B]
    | POST /match/enqueue {"player_id":"B", "mmr":1220}
    v
[Matcher]
    | ZADD match:queue 1220 "B"
    | process_queue() 호출
    | - A와 B 페어링 (MMR 차이 20)
    | - room_id = "room001", addr = "127.0.0.1:7777"
    | - HSET room_map:A room_id "room001", addr "127.0.0.1:7777"
    | - HSET room_map:B room_id "room001", addr "127.0.0.1:7777"
    | - ZREM match:queue A, B
    |
    | -> 클라이언트 A, B에게 HTTP 200 {"room_addr":"127.0.0.1:7777"}
    v
[클라이언트 A, B]
    | UDP 연결 to 127.0.0.1:7777
    v
[pong_udp Instance 1]
    | on_client_connect("A") -> 슬롯 배정 (left)
    | on_client_connect("B") -> 슬롯 배정 (right)
    | 게임 시작!
```

### 6.2 재접속 시나리오

```text
[클라이언트 A] (네트워크 끊김)
    | UDP 패킷 손실 -> timeout
    v
[pong_udp Instance 1]
    | 일정 시간(10초) 대기
    | player_slots_["A"].status = Reconnecting
    | 계속 게임 진행 (B는 AI 또는 대기 상태)
    |
[클라이언트 A] (3초 후 재접속 시도)
    | GET /match/status {"player_id":"A"}
    v
[Matcher]
    | HGETALL room_map:A
    | -> {"room_id":"room001", "addr":"127.0.0.1:7777"}
    | -> HTTP 200 {"room_addr":"127.0.0.1:7777"}
    v
[클라이언트 A]
    | UDP 연결 to 127.0.0.1:7777
    v
[pong_udp Instance 1]
    | on_client_connect("A")
    | - get_room_assignment("A") -> room_id 일치
    | - get_checkpoint("room001") -> 최신 스냅샷 복구
    | - player_slots_["A"].status = Active
    | - broadcast_roles() -> B에게 "A reconnected" 알림
    | 게임 계속!
```

### 6.3 체크포인트 갱신 흐름

```text
[pong_udp Instance 1] (매 틱)
    | tick 100 -> GameLoop::tick()
    | tick 100 % 5 == 0 -> 체크포인트 저장
    v
[Redis]
    | SET room:room001:checkpoint <binary_snapshot>
    | EXPIRE room:room001:checkpoint 30
    |
    | ... 5 틱 후 (tick 105) ...
    |
    | SET room:room001:checkpoint <new_snapshot>
    | EXPIRE room:room001:checkpoint 30  (TTL 갱신)
```

---

## 7. 부하 분산 & 확장성

### 7.1 Room Server 부하 분산

**전략: Least Loaded**
```cpp
std::string Matcher::get_available_room_server() {
    // Redis에서 모든 룸 서버 조회
    std::vector<std::string> servers = {"127.0.0.1:7777", "127.0.0.1:7778"};
    std::string least_loaded;
    int min_rooms = INT_MAX;

    for (auto& addr : servers) {
        int count = redis_hget("room_server:" + addr, "active_rooms");
        if (count < min_rooms) {
            min_rooms = count;
            least_loaded = addr;
        }
    }

    return least_loaded;
}
```

**Room Server 등록 (헬스체크):**
```cpp
void PongUdpServer::start() {
    // 주기적으로 Redis에 등록 (TTL 60초)
    heartbeat_timer_.async_wait([this](auto ec) {
        if (ec) return;
        room_manager_.register_room(room_id_, local_addr_, max_players_, 60);
        heartbeat_timer_.expires_after(std::chrono::seconds(30));
        // 30초마다 갱신 (TTL 60초보다 짧게)
    });
}
```

### 7.2 수평 확장 시나리오

**50 룸 동시 운영:**
```text
Matcher (1 인스턴스)
    |
    +-- pong_udp Instance 1 (Room 1~17)   : port 7777
    +-- pong_udp Instance 2 (Room 18~34)  : port 7778
    +-- pong_udp Instance 3 (Room 35~50)  : port 7779
        |
        v
      Redis (공유 상태)
```

**부하 테스트 검증:**
- 각 인스턴스: 17 룸 × 60 TPS = 1020 ticks/s
- 싱글 코어로 충분 (틱당 0.98ms)

---

## 8. 장애 처리 & 복구

### 8.1 Redis 장애 시나리오

**현상:**
- Matcher의 Redis 연결 실패 → `enqueue()` 실패
- Room Server의 체크포인트 저장 실패

**대응:**
```cpp
bool Matchmaker::enqueue(const std::string& player_id, int mmr) {
    try {
        redis_zadd("match:queue", mmr, player_id);
        return true;
    } catch (const RedisException& e) {
        std::cerr << "Redis error: " << e.what() << "\n";
        // 클라이언트에게 503 Service Unavailable 반환
        return false;
    }
}
```

**클라이언트 재시도:**
```cpp
void Client::enqueue_with_retry() {
    for (int i = 0; i < 3; ++i) {
        if (matcher_client_.enqueue(player_id_, mmr_)) {
            return;
        }
        std::this_thread::sleep_for(std::chrono::seconds(2 << i));  // 지수 백오프
    }
    throw std::runtime_error("Matcher unavailable");
}
```

### 8.2 Room Server 장애 시나리오

**현상:**
- 인스턴스 1 크래시 → Room 1~17 영향

**감지:**
- Redis TTL 만료 → Matcher가 해당 서버를 목록에서 제외
- 클라이언트 접속 시도 실패 → Matcher에게 에러 리포트

**복구:**
1. Room Server 재시작
2. Redis에 재등록 (`register_room`)
3. 기존 플레이어는 재접속 불가 (체크포인트 만료)
4. 새 매칭은 정상 배정

**개선 방향 (v1.4+):**
- 체크포인트를 영속 저장소(S3, PostgreSQL)에 백업
- 장애 서버의 룸을 다른 서버로 마이그레이션

---

## 9. 메트릭 & 모니터링 (v1.2 연계)

### 9.1 추가 메트릭

**Matcher 메트릭:**
```cpp
// PrometheusExporter에 추가
void set_match_queue_size(uint32_t size);
void observe_match_latency(double seconds);  // enqueue ~ 배정까지 시간
void inc_match_success_total();
void inc_match_timeout_total();  // 매칭 타임아웃 (대기 시간 초과)
```

**Room Server 메트릭:**
```cpp
void set_room_checkpoint_size(uint32_t bytes);
void inc_reconnect_success_total();
void inc_reconnect_failed_total();
void observe_checkpoint_restore_duration(double seconds);
```

### 9.2 Grafana 대시보드 패널 추가

- **Match Queue Size** (Gauge): `match_queue_size`
- **Match Latency p99** (Graph): `histogram_quantile(0.99, match_latency_seconds_bucket)`
- **Reconnection Success Rate**: `rate(reconnect_success_total) / rate(reconnect_total)`
- **Checkpoint Size** (Graph): `room_checkpoint_size` 추이

---

## 10. 성능 예산

### 10.1 Matcher 성능

**목표: 100 req/s**

| 단계 | 예상 시간 | 비고 |
|------|----------|------|
| HTTP 요청 파싱 | ~0.5ms | Boost.Beast |
| Redis ZADD | ~0.3ms | 로컬 Redis |
| 응답 생성 | ~0.2ms | JSON |
| **총** | **~1ms** | 100 req/s 충분 |

**병렬 처리:**
- HTTP 서버는 비동기 I/O (Boost.Asio)
- 동시 연결 수 제한 없음 (OS 한계까지)

### 10.2 Room Server 체크포인트 오버헤드

**5 틱마다 저장 (0.083초 주기):**
- 직렬화: ~0.5ms (protobuf)
- Redis SET: ~0.3ms
- **총**: ~0.8ms per checkpoint

**틱 예산 영향:**
- 5 틱 중 1 틱만 추가 0.8ms → 평균 0.16ms/tick
- 기존 예산 7.1ms에서 충분히 수용

---

## 11. 검증 전략

### 11.1 매치메이킹 테스트

**시나리오 1: 정상 매칭**
1. 10명의 봇 동시 enqueue (MMR 1000~1500)
2. `process_queue()` 호출
3. 5 페어 생성 확인
4. 각 페어의 MMR 차이 < 200 확인

**시나리오 2: MMR 불일치**
1. MMR 1000, 1500 두 명만 enqueue
2. 매칭 안 됨 (차이 500 > 200)
3. 큐에 계속 대기

### 11.2 재접속 테스트

**시나리오:**
1. 클라이언트 A, B 매칭 → 게임 시작
2. 틱 50에서 A 강제 종료
3. 틱 55에서 A 재접속 시도
4. 체크포인트 복구 → 틱 55부터 계속
5. 게임 정상 진행

**검증:**
- `reconnect_success_total` 카운터 증가
- A의 점수, 패들 위치 유지
- B가 "reconnected" 알림 수신

### 11.3 부하 테스트

**50 동시 룸:**
```bash
# 3 인스턴스 시작
./pong_udp --port 7777 --room-range 1-17 &
./pong_udp --port 7778 --room-range 18-34 &
./pong_udp --port 7779 --room-range 35-50 &

# Matcher 시작
./matcher --redis-host 127.0.0.1 --port 8080 &

# 100 클라이언트 매칭 시뮬레이션
./loadgen_matcher --clients 100 --duration 60
```

**검증:**
- 모든 인스턴스에서 60 TPS 유지
- Redis CPU < 10%
- Matcher 응답 시간 p99 < 50ms

---

## 12. 알려진 제약 & 향후 개선점

### 12.1 현재 제약

1. **단일 Redis 인스턴스**
   - SPOF (Single Point of Failure)
   - 개선: Redis Sentinel 또는 Redis Cluster

2. **체크포인트 휘발성**
   - 서버 재시작 시 30초 전 상태만 복구 가능
   - 개선: 영속 저장소에 백업 (S3, PostgreSQL)

3. **매칭 알고리즘 단순**
   - 단순 MMR 페어링만 지원
   - 개선: 대기 시간 고려, 파티 매칭, 지역별 매칭

### 12.2 최적화 기회

1. **Redis Pipeline**
   - 여러 명령을 한 번에 전송 → RTT 절감
   ```cpp
   redis_pipeline({
       {"ZADD", "match:queue", mmr, player_id},
       {"HSET", "session:" + token, "player_id", player_id}
   });
   ```

2. **체크포인트 압축**
   - LZ4로 스냅샷 압축 → Redis 메모리 절약

3. **매칭 우선순위**
   - 대기 시간 긴 플레이어 우선 매칭

---

## 13. 체크리스트 (v1.3 완료 기준)

- [ ] `Matchmaker` 클래스 구현 및 Redis 연동
- [ ] `RoomManager` 클래스 구현 (세션, 체크포인트)
- [ ] Matcher HTTP API 구현 (enqueue, dequeue, status)
- [ ] Redis 데이터 모델 검증 (키 명명, TTL)
- [ ] Room Server에서 체크포인트 주기적 저장
- [ ] 재접속 로직 구현 및 테스트
- [ ] 50 동시 룸에서 60 TPS 유지 확인
- [ ] 재접속 성공률 > 95% (3초 이내) 달성
- [ ] 세션 손실 0% 검증 (Redis 영속성)
- [ ] Matcher 처리량 > 100 req/s
- [ ] Redis 장애 시 503 + 백오프 동작 확인
- [ ] 부하 분산 (Least Loaded) 동작 확인
- [ ] 메트릭 추가 (match_queue_size, reconnect_*) 및 Grafana 패널
- [ ] 문서화: 아키텍처 다이어그램, API 명세, 재접속 가이드
