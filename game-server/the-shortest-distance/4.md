# 문서 4. netcode-core (실전 네트워크 게임 엔진)

> 이 문서는 **Stage 2** 용이다.
> 전제:
>
> * Stage 1까지 (gameserver-fundamentals Lab 1.1-1.4) 구현 완료
> * 이제 **UDP 기반 권위 서버**를 직접 만들고, 실전 네트워크 게임 엔진을 구축할 준비가 된 상태

---

## 0. 전제 / 목표

### 전제

* C++ 기본 문법 숙지
* CMake 빌드 시스템 사용 가능
* TCP/WebSocket 서버 구현 경험 (Lab 1.1-1.4)
* 멀티스레딩 기본 개념 이해

### 이 문서의 목표

1. **UDP 권위 서버** 아키텍처 이해
2. **신뢰성 레이어** 구현 (재전송, ACK, 순서 보장)
3. **스냅샷 & 델타 압축**으로 대역폭 최적화
4. **Prometheus 메트릭**으로 서버 성능 모니터링
5. **매치메이킹 시스템**으로 플레이어 자동 매칭

---

## 1. netcode-core 프로젝트 구조

### 1.1 디렉토리 구조

```text
netcode-core/
├── proto/
│   └── mini.proto           # Protobuf 메시지 정의
├── core/
│   ├── clock.hpp            # 시간 측정
│   └── counters.hpp         # 메트릭 카운터
├── net/
│   ├── endpoint.hpp         # IP:Port 추상화
│   ├── itransport.hpp       # 전송 계층 인터페이스
│   └── udp_transport.hpp    # UDP 구현
├── sync/
│   ├── snapshot.hpp         # 스냅샷 인코딩
│   └── delta.hpp            # 델타 압축
├── match/
│   ├── matcher.hpp          # 매치메이커
│   └── room.hpp             # 방 관리
├── metrics/
│   └── prometheus.hpp       # Prometheus 메트릭
└── apps/
    ├── pong_udp/            # Pong 게임 서버
    ├── matcher/             # 매치 서버
    └── loadgen/             # 부하 테스트 생성기
```

### 1.2 빌드 방법

```bash
cd netcode-core
mkdir build
cd build
cmake ..
make -j4

# 실행 파일 위치
ls apps/pong_udp/bin/pong_server
ls apps/matcher/bin/matcher_server
```

---

## 2. v1.0: UDP 권위 서버 & 신뢰성 레이어

### 2.1 목표

* UDP 소켓으로 클라이언트 통신
* 시퀀스 번호, ACK, ACK 비트마스크 구현
* 재전송 큐 + 타임아웃 관리
* 패킷 필터링 (중복, 오래된 패킷)

### 2.2 왜 UDP인가?

**TCP/WebSocket의 한계**:

* **Head-of-Line Blocking**: 한 패킷 손실 시 이후 패킷 모두 대기
* 실시간 게임에서는 오래된 상태보다 최신 상태가 중요
* 불필요한 재전송으로 지연 증가

**UDP의 장점**:

* 패킷 단위 독립 처리
* 오래된 상태 패킷은 과감히 버릴 수 있음
* 송신 즉시 전달

**트레이드오프**:

* 패킷 손실, 순서 뒤바뀜, 중복 전달을 직접 처리해야 함
* 최소한의 신뢰성 레이어 필요

### 2.3 UDP 패킷 구조

```text
┌────────────────────────────────────┐
│ UdpHeader (8 bytes)                │
│  - seq      (uint16, 2 bytes)      │
│  - ack      (uint16, 2 bytes)      │
│  - ack_bits (uint32, 4 bytes)      │
├────────────────────────────────────┤
│ Payload (protobuf 직렬화 메시지)    │
│  - Input / World / ServerAck 등    │
└────────────────────────────────────┘
```

### 2.4 시퀀스 번호 & ACK 비트마스크

**시퀀스 번호**:

* 범위: 0 ~ 65535 (uint16)
* 순환: 65535 다음은 0
* 비교 함수: `is_seq_newer(lhs, rhs)`

**ACK 비트마스크**:

* `ack`: 수신한 가장 최신 시퀀스
* `ack_bits`: `ack` 이전 32개 패킷의 수신 비트마스크

```
ack = 100, ack_bits = 0b...1011
-> seq 100 수신 (ack)
-> seq 99 수신 (bit 0 = 1)
-> seq 98 손실 (bit 1 = 0)
-> seq 97 수신 (bit 2 = 1)
-> seq 96 수신 (bit 3 = 1)
```

### 2.5 ITransport 인터페이스

```cpp
class ITransport {
public:
    virtual void start(ReceiveHandler handler) = 0;
    virtual void stop() = 0;
    virtual void send(const Endpoint&, std::vector<uint8_t> data, bool reliable) = 0;
    virtual void update() = 0;  // 재전송 처리 등
    virtual void set_metrics_enabled(bool enabled) = 0;
    virtual Counters sample_counters() const = 0;
};
```

### 2.6 UdpTransport 구현

```cpp
class UdpTransport : public ITransport {
public:
    explicit UdpTransport(uint16_t port);

    void start(ReceiveHandler handler) override;
    void stop() override;
    void send(const Endpoint& ep, std::vector<uint8_t> data, bool reliable) override;
    void update() override;

private:
    void receive_loop();
    void process_acks(const Endpoint& ep, uint16_t ack, uint32_t ack_bits);
    void resend_timed_out_packets();

    int socket_fd_;
    std::atomic<bool> running_;
    std::thread receive_thread_;

    // 클라이언트별 송수신 상태
    std::map<Endpoint, SendState> send_states_;
    std::map<Endpoint, ReceiveState> recv_states_;
    std::mutex states_mutex_;
};
```

### 2.7 재전송 로직

```cpp
void UdpTransport::update() {
    auto now = Clock::now();

    std::lock_guard<std::mutex> lock(states_mutex_);
    for (auto& [ep, state] : send_states_) {
        for (auto& pkt : state.pending_packets) {
            if (now >= pkt.next_send) {
                // 재전송
                send_raw(ep, pkt.payload);
                pkt.last_sent = now;
                pkt.next_send = now + timeout_duration;
                pkt.retries++;

                if (pkt.retries > max_retries) {
                    // 타임아웃
                    counters_.reliable_timeouts_total++;
                    // 패킷 제거
                }
            }
        }
    }
}
```

---

## 3. v1.1: 스냅샷 & 델타 압축

### 3.1 목표

* Protobuf로 메시지 정의
* 전체 스냅샷 vs 델타 스냅샷
* 클라이언트측 예측/보간
* 대역폭 측정

### 3.2 Protobuf 메시지 정의

```protobuf
// proto/mini.proto
syntax = "proto3";

message Vec2 {
    float x = 1;
    float y = 2;
}

message Ball {
    Vec2 position = 1;
    Vec2 velocity = 2;
}

message Paddle {
    float y = 1;
}

message WorldSnapshot {
    uint32 tick = 1;
    Ball ball = 2;
    Paddle paddle1 = 3;
    Paddle paddle2 = 4;
    int32 score1 = 5;
    int32 score2 = 6;
}

message InputMessage {
    uint32 tick = 1;
    string action = 2;  // "up", "down", "none"
}
```

### 3.3 스냅샷 vs 델타

**전체 스냅샷** (Baseline):

* 모든 상태 정보 포함
* 클라이언트 최초 접속 시 전송
* 주기적으로 전송 (예: 1초마다)

**델타 스냅샷**:

* 이전 스냅샷 대비 변경된 필드만 전송
* 대역폭 절약
* 패킷 손실 시 다음 Baseline까지 대기

```cpp
class SnapshotEncoder {
public:
    std::vector<uint8_t> encode_full(const WorldSnapshot& snapshot);
    std::vector<uint8_t> encode_delta(const WorldSnapshot& current, const WorldSnapshot& baseline);
};

class SnapshotDecoder {
public:
    WorldSnapshot decode_full(const std::vector<uint8_t>& data);
    WorldSnapshot decode_delta(const std::vector<uint8_t>& data, const WorldSnapshot& baseline);
};
```

### 3.4 클라이언트측 예측/보간

**예측 (Client-side Prediction)**:

* 클라이언트가 입력을 즉시 로컬에 적용
* 서버 응답 대기 없이 즉각적인 피드백
* 서버 상태 수신 시 조정 (Reconciliation)

**보간 (Interpolation)**:

* 서버에서 받은 스냅샷 사이를 부드럽게 이어줌
* 렌더 시각을 실제보다 약간 지연 (예: 100ms)
* 자연스러운 움직임 제공

```javascript
// 클라이언트 예시 (JavaScript)
function update(dt) {
    // 1. 로컬 입력 예측
    applyInput(localInput);

    // 2. 서버 스냅샷 보간
    const renderTime = now() - 100;  // 100ms 지연
    const s1 = getSnapshotBefore(renderTime);
    const s2 = getSnapshotAfter(renderTime);
    const t = (renderTime - s1.time) / (s2.time - s1.time);
    const interpolated = lerp(s1, s2, t);

    // 3. 렌더링
    render(interpolated);
}
```

---

## 4. v1.2: 메트릭 & 모니터링

### 4.1 목표

* Prometheus C++ 클라이언트 통합
* 커스텀 카운터/히스토그램
* `/metrics` HTTP 엔드포인트
* Grafana 대시보드

### 4.2 Prometheus 메트릭

**카운터**:

* `reliable_retries_total`: 재전송된 패킷 수
* `reliable_timeouts_total`: 타임아웃으로 폐기된 패킷 수
* `dropped_duplicates_total`: 중복 패킷 드롭 수

**히스토그램**:

* `server_tick_duration_seconds`: 서버 틱 처리 시간
* `packet_size_bytes`: 패킷 크기 분포

```cpp
#include <prometheus/counter.h>
#include <prometheus/histogram.h>
#include <prometheus/registry.h>

class MetricsCollector {
public:
    MetricsCollector();

    void increment_retries();
    void observe_tick_duration(double seconds);

private:
    prometheus::Registry registry_;
    prometheus::Counter& retries_counter_;
    prometheus::Histogram& tick_histogram_;
};
```

### 4.3 /metrics 엔드포인트

```cpp
#include <prometheus/exposer.h>

int main() {
    // Prometheus Exposer (HTTP 서버)
    prometheus::Exposer exposer{"0.0.0.0:9090"};

    // Registry 등록
    auto registry = std::make_shared<prometheus::Registry>();
    exposer.RegisterCollectable(registry);

    // 게임 서버 실행
    PongServer server(8000, registry);
    server.run();

    return 0;
}
```

**테스트**:

```bash
# 메트릭 확인
curl http://localhost:9090/metrics

# 출력 예시:
# reliable_retries_total 142
# reliable_timeouts_total 3
# server_tick_duration_seconds_bucket{le="0.01"} 9850
# server_tick_duration_seconds_bucket{le="0.015"} 9998
```

### 4.4 Grafana 대시보드

**주요 패널**:

* **서버 처리 지연** (p50/p95/p99)
* **패킷 손실률** (`reliable_timeouts_total / 전체 전송`)
* **재전송 횟수** (`reliable_retries_total`)
* **동시 접속자 수**

---

## 5. v1.3: 매치메이킹 & 방 분리

### 5.1 목표

* 매치 서버 (별도 프로세스)
* PostgreSQL 매치 큐
* Redis 방 관리
* 게임 서버와 매치 서버 통신

### 5.2 아키텍처

```text
[클라이언트]
    │
    │ HTTP POST /match/request
    ▼
[매치 서버]
    │
    ├─ PostgreSQL (매치 큐, 플레이어 정보)
    ├─ Redis (방 상태, 세션)
    │
    │ 매칭 완료 시
    ▼
[게임 서버]
    │
    │ UDP
    ▼
[클라이언트]
```

### 5.3 매치 서버 API

**매칭 요청**:

```
POST /match/request
Content-Type: application/json

{
    "player_id": "p123",
    "rating": 1500
}
```

**응답**:

```json
{
    "match_id": "m456",
    "room_id": "r789",
    "game_server": "game1.example.com:9000",
    "opponent_id": "p124"
}
```

### 5.4 PostgreSQL 스키마

```sql
CREATE TABLE players (
    id VARCHAR(32) PRIMARY KEY,
    rating INT NOT NULL,
    created_at TIMESTAMP NOT NULL DEFAULT NOW()
);

CREATE TABLE match_queue (
    player_id VARCHAR(32) PRIMARY KEY REFERENCES players(id),
    rating INT NOT NULL,
    queued_at TIMESTAMP NOT NULL DEFAULT NOW()
);

CREATE TABLE matches (
    id VARCHAR(32) PRIMARY KEY,
    player1_id VARCHAR(32) NOT NULL,
    player2_id VARCHAR(32) NOT NULL,
    room_id VARCHAR(32) NOT NULL,
    game_server VARCHAR(128) NOT NULL,
    started_at TIMESTAMP NOT NULL DEFAULT NOW()
);
```

### 5.5 Redis 방 관리

```cpp
#include <hiredis/hiredis.h>

class RoomManager {
public:
    RoomManager(const std::string& redis_url);

    std::string create_room(const std::string& match_id);
    bool add_player_to_room(const std::string& room_id, const std::string& player_id);
    void close_room(const std::string& room_id);

private:
    redisContext* redis_;
};
```

**Redis 키 구조**:

```
room:<room_id>:players = SET {player1_id, player2_id}
room:<room_id>:match_id = STRING match_id
room:<room_id>:status = STRING "waiting" | "playing" | "finished"
```

### 5.6 매칭 알고리즘 (간단 버전)

```cpp
void Matcher::tick() {
    auto queued_players = db_.get_queued_players();

    // 레이팅 기준 정렬
    std::sort(queued_players.begin(), queued_players.end(),
              [](const auto& a, const auto& b) { return a.rating < b.rating; });

    // 인접한 플레이어끼리 매칭
    for (size_t i = 0; i + 1 < queued_players.size(); i += 2) {
        const auto& p1 = queued_players[i];
        const auto& p2 = queued_players[i + 1];

        // 레이팅 차이 체크
        if (std::abs(p1.rating - p2.rating) > max_rating_diff) {
            continue;
        }

        // 매칭 생성
        create_match(p1.id, p2.id);

        // 큐에서 제거
        db_.remove_from_queue(p1.id);
        db_.remove_from_queue(p2.id);
    }
}
```

---

## 6. Stage 2 체크리스트

이 문서 기준으로, 아래를 만족하면 Stage 2의 "netcode-core"는 통과로 본다.

* [ ] v1.0: UDP 소켓으로 클라이언트와 통신하고, 시퀀스 번호/ACK 비트마스크를 구현했다.
* [ ] v1.0: 3% 패킷 손실 환경에서도 중요한 메시지(입력, 점수)가 재전송을 통해 전달되는 것을 확인했다.
* [ ] v1.1: Protobuf로 메시지를 직렬화하고, 델타 스냅샷으로 대역폭을 절약했다.
* [ ] v1.1: 클라이언트측 예측/보간을 구현해서 부드러운 움직임을 제공했다.
* [ ] v1.2: Prometheus 메트릭을 `/metrics` 엔드포인트로 노출하고, Grafana에서 실시간으로 모니터링할 수 있다.
* [ ] v1.2: 서버 처리 지연 p99 < 15ms를 달성했다.
* [ ] v1.3: 매치 서버에서 플레이어를 자동으로 매칭하고, 게임 서버 주소를 반환하여 게임을 시작할 수 있다.
* [ ] v1.3: PostgreSQL과 Redis를 사용해서 매치 큐와 방 관리를 구현했다.

여기까지 구현하면:

* **TCP/WebSocket 기반 기본 서버** (Lab 1.1-1.4)
* **UDP 기반 권위 서버 + 신뢰성 레이어** (v1.0)
* **스냅샷 & 델타 압축** (v1.1)
* **메트릭 & 모니터링** (v1.2)
* **매치메이킹 시스템** (v1.3)

까지 **실전 네트워크 게임 엔진의 전체 그림**이 완성된 상태다.
