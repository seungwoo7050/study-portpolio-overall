# 관측성 & 재현 가능한 부하 테스트 설계 일지 (v1.2)
> 메트릭, 대시보드, 부하 테스트를 통해 시스템을 수치화하고 성능 이슈를 조기 발견

## 1. 문제 정의 & 요구사항

### 1.1 v1.0-1.1의 관측 한계

**현재 상황:**
- 서버가 60 TPS로 동작하는지 **눈대중으로 확인**
- 패킷 손실, 재전송 빈도를 **로그로만 추적**
- 성능 문제 발생 시 **재현 불가** (어떤 조건에서 발생했는지 모름)
- 부하 테스트가 **비체계적** (수동으로 클라이언트 실행, 결과 기록 없음)

**결과:**
- 프로덕션 배포 후 문제가 터지면 **사후 대응**만 가능
- "왜 p99 지연이 증가했는가?" → **데이터 없음**
- "100 동시 사용자일 때 안정적인가?" → **테스트 안 해봄**

### 1.2 목표

#### 1.2.1 메트릭 시스템 구축
- **Prometheus** 기반 메트릭 수집
  - 게임 서버 내부 메트릭 export (HTTP /metrics 엔드포인트)
  - 표준 Prometheus 텍스트 포맷
- **핵심 메트릭 정의**:
  - 게임: `game_tick_rate`, `game_tick_duration_seconds`
  - 네트워크: `rtt_ms_p50`, `rtt_ms_p99`, `dropped_packets_total`, `retransmit_total`
  - 상태: `rooms_active`, `players_active`
  - 동기화: `resimulations_total`, `resim_depth_bucket`

#### 1.2.2 Grafana 대시보드
- 실시간 메트릭 시각화
- SLO (Service Level Objective) 기준 표시
- 알람 설정 (예: p99 > 15ms 지속 시 알림)

#### 1.2.3 재현 가능한 부하 테스트
- **loadgen** 도구 구현:
  - N개 봇 클라이언트 시뮬레이션
  - RTT/손실 파라미터 제어
  - CSV 형식 결과 출력
- **Soak 테스트**: 200 클라이언트, 2~4시간 동안 안정성 검증
- **성능 회귀 방지**: 매 PR마다 자동 부하 테스트 실행

### 1.3 비기능 요구사항

#### 1.3.1 메트릭 오버헤드
- 메트릭 수집 자체가 성능에 미치는 영향 < 1% (틱당 < 0.16ms)
- 메모리 오버헤드 < 10 MB

#### 1.3.2 대시보드 응답 속도
- Grafana 쿼리 응답 < 1초
- Prometheus scrape 간격: 5초 (기본)

#### 1.3.3 부하 테스트 재현성
- 동일한 파라미터로 테스트 재실행 시 결과 편차 < 5%
- 테스트 결과 자동 저장 (CSV + 메타데이터)

---

## 2. 기술적 배경 & 설계 동기

### 2.1 왜 Prometheus인가?

**대안 비교:**
| 도구 | 장점 | 단점 |
|------|------|------|
| Prometheus | 풀 기반, 간단한 설정, 강력한 쿼리(PromQL) | 장기 저장에는 부적합 (기본 15일) |
| Graphite | 푸시 기반, 유연한 메트릭 구조 | 설정 복잡, 쿼리 기능 약함 |
| StatsD | 경량, 푸시 기반 | 시각화 별도 필요, 히스토그램 지원 약함 |
| CloudWatch | AWS 네이티브, 알람 통합 | 비용, 클라우드 종속 |

**선택 이유:**
- 로컬 개발에서도 `docker-compose`로 쉽게 실행
- Grafana와 네이티브 연동
- 히스토그램/백분위수 쿼리 지원
- 무료/오픈소스

### 2.2 메트릭 타입 이해

**Prometheus 4가지 메트릭 타입:**

1. **Counter** (누적 값, 증가만 가능)
   - 예: `dropped_packets_total`, `retransmit_total`
   - PromQL: `rate(counter[1m])` → 초당 증가율

2. **Gauge** (현재 값, 증감 자유)
   - 예: `game_tick_rate`, `rooms_active`
   - PromQL: `avg_over_time(gauge[5m])` → 5분 평균

3. **Histogram** (값 분포, 버킷 기반)
   - 예: `game_tick_duration_seconds`
   - 자동으로 `_sum`, `_count`, `_bucket{le="..."}` 생성
   - PromQL: `histogram_quantile(0.99, ...)` → p99

4. **Summary** (클라이언트가 백분위 계산)
   - 예: `resim_depth_summary{quantile="0.5"}`
   - 백분위를 서버가 미리 계산 (Prometheus는 집계만)

**선택 기준:**
- 누적 카운트 → Counter
- 실시간 상태 → Gauge
- 지연 분포 분석 → Histogram (서버 p99 계산 가능)

---

## 3. PrometheusExporter 설계

### 3.1 클래스 구조

```cpp
namespace metrics {

class PrometheusExporter {
public:
    PrometheusExporter();
    ~PrometheusExporter();

    // HTTP 서버 시작/종료
    void start(uint16_t port);
    void stop();

    // Gauge 메트릭
    void set_game_tick_rate(double tps);
    void set_rtt_p50(double ms);
    void set_rtt_p99(double ms);
    void set_rooms_active(uint32_t count);
    void set_players_active(uint32_t count);

    // Counter 메트릭
    void inc_dropped_packets(const std::string& reason, uint64_t count = 1);
    void inc_retransmit_total(uint64_t count = 1);
    void inc_resimulations_total(uint64_t count = 1);

    // Histogram 메트릭
    void observe_tick_duration(double seconds);
    void observe_resim_depth(uint32_t depth);

    // /metrics 엔드포인트용
    std::string get_metrics() const;

private:
    struct Histogram {
        std::vector<double> values;
        std::map<double, uint64_t> buckets;  // {le: count}
        void observe(double value);
        double percentile(double p) const;
        void clear();
    };

    mutable std::mutex mutex_;

    // Gauges (atomic으로 빠른 읽기)
    std::atomic<double> game_tick_rate_{0.0};
    std::atomic<double> rtt_p50_{0.0};
    std::atomic<double> rtt_p99_{0.0};
    std::atomic<uint32_t> rooms_active_{0};
    std::atomic<uint32_t> players_active_{0};

    // Counters
    std::map<std::string, uint64_t> dropped_packets_;  // reason별 카운트
    std::atomic<uint64_t> retransmit_total_{0};
    std::atomic<uint64_t> resimulations_total_{0};

    // Histograms
    Histogram tick_duration_hist_;
    Histogram resim_depth_hist_;

    // HTTP 서버
    std::atomic<bool> running_{false};
    uint16_t port_{0};
    std::thread server_thread_;
    void run_http_server();
};

} // namespace metrics
```

### 3.2 Prometheus 텍스트 포맷

`get_metrics()` 구현 예시:
```cpp
std::string PrometheusExporter::get_metrics() const {
    std::ostringstream oss;

    // HELP/TYPE 정의
    oss << "# HELP game_tick_rate Current game server tick rate\n";
    oss << "# TYPE game_tick_rate gauge\n";
    oss << "game_tick_rate " << game_tick_rate_.load() << "\n\n";

    oss << "# HELP game_tick_duration_seconds Histogram of tick durations\n";
    oss << "# TYPE game_tick_duration_seconds histogram\n";
    {
        std::lock_guard<std::mutex> lock(mutex_);
        for (const auto& [le, count] : tick_duration_hist_.buckets) {
            oss << "game_tick_duration_seconds_bucket{le=\"" << le << "\"} " << count << "\n";
        }
        oss << "game_tick_duration_seconds_bucket{le=\"+Inf\"} " << tick_duration_hist_.values.size() << "\n";
        oss << "game_tick_duration_seconds_sum " << std::accumulate(...) << "\n";
        oss << "game_tick_duration_seconds_count " << tick_duration_hist_.values.size() << "\n";
    }
    oss << "\n";

    oss << "# HELP dropped_packets_total Total packets dropped by reason\n";
    oss << "# TYPE dropped_packets_total counter\n";
    {
        std::lock_guard<std::mutex> lock(mutex_);
        for (const auto& [reason, count] : dropped_packets_) {
            oss << "dropped_packets_total{reason=\"" << reason << "\"} " << count << "\n";
        }
    }
    oss << "\n";

    // 나머지 메트릭들...

    return oss.str();
}
```

### 3.3 HTTP 서버 (간단한 구현)

```cpp
void PrometheusExporter::run_http_server() {
    int server_fd = socket(AF_INET, SOCK_STREAM, 0);
    // bind, listen ...

    while (running_.load()) {
        int client_fd = accept(server_fd, ...);
        if (client_fd < 0) continue;

        // HTTP 요청 읽기 (간단히 GET /metrics만 처리)
        char buffer[1024];
        read(client_fd, buffer, sizeof(buffer));

        // HTTP 응답
        std::string metrics = get_metrics();
        std::ostringstream response;
        response << "HTTP/1.1 200 OK\r\n";
        response << "Content-Type: text/plain; version=0.0.4\r\n";
        response << "Content-Length: " << metrics.size() << "\r\n";
        response << "\r\n";
        response << metrics;

        write(client_fd, response.str().c_str(), response.str().size());
        close(client_fd);
    }
}
```

**참고**: 프로덕션에서는 `beast::http` 같은 라이브러리 사용 권장.

---

## 4. 핵심 메트릭 정의 & SLO

### 4.1 게임 루프 메트릭

#### `game_tick_rate` (Gauge)
- **의미**: 현재 서버 틱 레이트 (TPS)
- **수집 방법**: 최근 10 틱의 평균 간격으로 계산
  ```cpp
  void GameLoop::tick() {
      auto now = Clock::now();
      if (last_tick_time_.has_value()) {
          auto dt = std::chrono::duration<double>(now - *last_tick_time_).count();
          double tps = 1.0 / dt;
          exporter_.set_game_tick_rate(tps);
      }
      last_tick_time_ = now;
  }
  ```
- **SLO**: 59.0 ≤ TPS ≤ 61.0 (±1 허용)

#### `game_tick_duration_seconds` (Histogram)
- **의미**: 틱 처리 시간 분포
- **버킷**: 0.005, 0.010, 0.015, 0.020, 0.030, +Inf (단위: 초)
- **수집 방법**:
  ```cpp
  auto start = Clock::now();
  // ... 틱 로직 ...
  auto end = Clock::now();
  double duration = std::chrono::duration<double>(end - start).count();
  exporter_.observe_tick_duration(duration);
  ```
- **SLO**: p99 < 0.015 (15ms)

### 4.2 네트워크 메트릭

#### `rtt_ms_p50`, `rtt_ms_p99` (Gauge)
- **의미**: 클라이언트 RTT 중앙값/99백분위
- **수집 방법**: `input-ack` 전송 시 `latency_ms` 값 수집
  ```cpp
  void on_input_ack(double latency_ms) {
      rtt_samples_.push_back(latency_ms);
      if (rtt_samples_.size() >= 100) {
          std::sort(rtt_samples_.begin(), rtt_samples_.end());
          double p50 = rtt_samples_[50];
          double p99 = rtt_samples_[99];
          exporter_.set_rtt_p50(p50);
          exporter_.set_rtt_p99(p99);
          rtt_samples_.clear();
      }
  }
  ```
- **SLO**: p99 < 200ms (네트워크 환경 가정)

#### `dropped_packets_total{reason}` (Counter)
- **의미**: 드롭된 패킷 누적 수 (이유별)
- **레이블**: `reason="duplicate"`, `"old"`, `"window"`
- **수집 방법**: `UdpTransport`에서 드롭 시 호출
  ```cpp
  void log_drop(const std::string& reason) {
      dropped_old_total_++;  // v1.0 기존 카운터
      exporter_.inc_dropped_packets(reason);  // v1.2 추가
  }
  ```
- **SLO**: `rate(dropped_packets_total[1m])` < 틱 레이트의 5% (손실 환경 고려)

#### `retransmit_total` (Counter)
- **의미**: 재전송된 패킷 누적 수
- **수집**: `UdpTransport::update()` 재전송 시
- **SLO**: 3% 손실 환경에서 `rate(retransmit_total[1m])` ≈ 전송량의 3~5%

### 4.3 동기화 메트릭

#### `resimulations_total` (Counter)
- **의미**: 클라이언트 리컨실리에이션 발생 횟수
- **수집**: `PredictiveClient::reconcile()` 불일치 감지 시
- **SLO**: `rate(resimulations_total[1m])` < 틱 레이트의 10% (예측 정확도 90%+)

#### `resim_depth_bucket` (Histogram)
- **의미**: 리심 깊이 분포
- **버킷**: 0, 1, 2, 5, 10, +Inf
- **수집**:
  ```cpp
  void reconcile() {
      uint64_t depth = local_tick_ - server_state.tick;
      exporter_.observe_resim_depth(depth);
  }
  ```
- **SLO**: 99%의 리심이 깊이 ≤ 2 틱

### 4.4 상태 메트릭

#### `rooms_active`, `players_active` (Gauge)
- **의미**: 현재 활성 룸/플레이어 수
- **수집**: 매 틱마다 또는 변경 시
  ```cpp
  void update_metrics() {
      exporter_.set_rooms_active(rooms_.size());
      exporter_.set_players_active(count_active_players());
  }
  ```
- **SLO**: `players_active` / `rooms_active` ≈ 2 (2인 Pong 기준)

---

## 5. Grafana 대시보드 설계

### 5.1 대시보드 구성

**패널 레이아웃 (4행 × 2열):**

| 행 | 패널 1 | 패널 2 |
|----|--------|--------|
| 1 | **Game Tick Rate** (Gauge) | **Tick Duration p99** (Graph) |
| 2 | **Active Players** (Stat) | **RTT p50/p99** (Graph) |
| 3 | **Dropped Packets Rate** (Graph, reason별) | **Retransmit Rate** (Graph) |
| 4 | **Resim Rate** (Graph) | **Resim Depth Distribution** (Heatmap) |

### 5.2 PromQL 쿼리 예시

**Tick Duration p99:**
```promql
histogram_quantile(0.99,
  rate(game_tick_duration_seconds_bucket[1m])
)
```

**Dropped Packets Rate (reason별):**
```promql
sum by (reason) (
  rate(dropped_packets_total[1m])
)
```

**Resim Rate (초당 리심 횟수):**
```promql
rate(resimulations_total[1m])
```

**Resim Depth Distribution:**
```promql
sum by (le) (
  rate(resim_depth_bucket[5m])
)
```

### 5.3 알람 설정

**예시 1: Tick p99 초과**
```yaml
alert: HighTickDuration
expr: histogram_quantile(0.99, rate(game_tick_duration_seconds_bucket[5m])) > 0.015
for: 2m
annotations:
  summary: "Tick p99 지연이 15ms를 초과했습니다"
```

**예시 2: 플레이어 수 급감**
```yaml
alert: PlayerDropoff
expr: rate(players_active[5m]) < -10
for: 1m
annotations:
  summary: "플레이어 수가 급격히 감소했습니다"
```

---

## 6. loadgen 부하 테스트 도구

### 6.1 요구사항

- N개 봇 클라이언트 병렬 실행
- 각 봇은 실제 클라이언트처럼 동작:
  - UDP로 서버 접속
  - 주기적으로 입력 전송 (랜덤 방향)
  - 서버 상태 수신
- RTT/손실 파라미터 제어 (netem 또는 로컬 시뮬레이션)
- 결과 CSV 출력:
  - 봇별 RTT, 패킷 손실률, 수신한 상태 수
  - 서버 메트릭 샘플링 (Prometheus scrape)

### 6.2 구조

```cpp
class Bot {
public:
    Bot(int bot_id, const std::string& server_addr, uint16_t server_port);

    void start();
    void stop();

    struct Stats {
        uint64_t packets_sent{0};
        uint64_t packets_received{0};
        double avg_rtt_ms{0.0};
        double max_rtt_ms{0.0};
    };

    Stats get_stats() const;

private:
    void run();
    void send_input();
    void receive_state();

    int bot_id_;
    UdpTransport transport_;
    std::thread thread_;
    std::atomic<bool> running_{false};
    Stats stats_;
};

class LoadGen {
public:
    LoadGen(int num_bots, const std::string& server_addr, uint16_t server_port, int duration_sec);

    void run();
    void print_results();
    void export_csv(const std::string& path);

private:
    std::vector<std::unique_ptr<Bot>> bots_;
    int duration_sec_;
};
```

### 6.3 실행 예시

```bash
# 200 클라이언트, 60초 테스트
./loadgen --clients 200 --server 127.0.0.1:7777 --duration 60 --output results.csv

# netem 손실 3%, RTT 60ms 환경
sudo tc qdisc add dev lo root netem loss 3% delay 30ms
./loadgen --clients 200 --duration 60
sudo tc qdisc del dev lo root
```

**출력 예시 (results.csv):**
```csv
bot_id,packets_sent,packets_received,loss_rate,avg_rtt_ms,max_rtt_ms
0,3600,3492,3.0%,62.3,120.5
1,3600,3510,2.5%,61.8,115.2
...
```

### 6.4 Soak 테스트 자동화

`scripts/soak_test.sh`:
```bash
#!/bin/bash
set -e

CLIENTS=200
DURATION=7200  # 2시간

echo "Starting soak test: $CLIENTS clients, $DURATION seconds"

# 서버 시작
./pong_udp --metrics-port 9090 &
SERVER_PID=$!

sleep 5

# Prometheus scraping 시작 (백그라운드)
while true; do
    curl -s http://localhost:9090/metrics > metrics_$(date +%s).txt
    sleep 60
done &
SCRAPER_PID=$!

# loadgen 실행
./loadgen --clients $CLIENTS --duration $DURATION --output soak_results.csv

# 정리
kill $SCRAPER_PID
kill $SERVER_PID

# 결과 분석
echo "=== Soak Test Results ==="
python3 scripts/analyze_soak.py soak_results.csv metrics_*.txt
```

**analyze_soak.py 예시:**
- RSS 메모리 증가율 계산 (< 2% 허용)
- FD 카운트 변화 (안정적이어야 함)
- p99 틱 지연 추이 (< 15ms 유지)
- 봇별 패킷 손실률 통계

---

## 7. Docker Compose 로컬 환경

`deployments/docker/docker-compose.yml`:
```yaml
version: '3.8'

services:
  prometheus:
    image: prom/prometheus:latest
    ports:
      - "9091:9090"
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus-data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.retention.time=15d'

  grafana:
    image: grafana/grafana:latest
    ports:
      - "3000:3000"
    volumes:
      - grafana-data:/var/lib/grafana
      - ./grafana/dashboards:/etc/grafana/provisioning/dashboards
      - ./grafana/datasources:/etc/grafana/provisioning/datasources
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin

  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"

volumes:
  prometheus-data:
  grafana-data:
```

`prometheus.yml`:
```yaml
global:
  scrape_interval: 5s

scrape_configs:
  - job_name: 'pong_udp'
    static_configs:
      - targets: ['host.docker.internal:9090']
```

**실행:**
```bash
cd netcode-core
docker-compose -f deployments/docker/docker-compose.yml up -d

# 게임 서버 실행
./build/apps/pong_udp/pong_udp --metrics-port 9090

# Grafana 접속: http://localhost:3000 (admin/admin)
```

---

## 8. 성능 회귀 방지 (CI 통합)

### 8.1 GitHub Actions에 부하 테스트 추가

`.github/workflows/ci.yml`:
```yaml
jobs:
  performance-test:
    runs-on: ubuntu-latest
    steps:
      - name: Build
        run: cmake --build build/netcode-core --config Release

      - name: Start server
        run: |
          ./build/apps/pong_udp/pong_udp --metrics-port 9090 &
          echo $! > server.pid
          sleep 2

      - name: Run load test
        run: |
          ./build/apps/loadgen/loadgen \
            --clients 50 --duration 30 --output perf_results.csv

      - name: Analyze results
        run: |
          python3 scripts/check_perf_regression.py perf_results.csv
          # p99 > 15ms이면 실패

      - name: Stop server
        run: kill $(cat server.pid)
```

**check_perf_regression.py 예시:**
```python
import sys
import pandas as pd

df = pd.read_csv(sys.argv[1])
avg_rtt = df['avg_rtt_ms'].mean()
max_rtt = df['max_rtt_ms'].max()

if max_rtt > 15.0:
    print(f"FAIL: max RTT {max_rtt}ms > 15ms")
    sys.exit(1)

print(f"PASS: avg RTT {avg_rtt}ms, max {max_rtt}ms")
```

---

## 9. 검증 전략

### 9.1 메트릭 정확성 테스트

**시나리오 1: Tick Rate 검증**
1. 서버 시작, 60 TPS로 10초 동안 실행
2. Prometheus `/metrics` 스크랩
3. `game_tick_rate` 값이 59~61 범위인지 확인

**시나리오 2: Histogram 버킷**
1. 틱 처리 시간을 의도적으로 10ms로 고정
2. 100 틱 실행 후 `/metrics` 확인
3. `game_tick_duration_seconds_bucket{le="0.015"}` 카운트가 100인지 확인

### 9.2 부하 테스트 재현성

**실험:**
1. 동일 파라미터로 loadgen 3회 실행
   - 50 클라이언트, 60초, 손실 0%
2. 각 실행의 평균 RTT 비교
3. 표준편차 < 평균의 5%인지 확인

### 9.3 Soak 테스트 안정성

**목표:**
- 200 클라이언트, 2시간 동안 안정 동작
- RSS 증가 < 2%
- FD 카운트 안정 (±5개 이내)
- p99 틱 지연 < 15ms 유지

**검증 스크립트:**
```bash
# 매 5분마다 메트릭 수집
for i in {1..24}; do
    curl -s http://localhost:9090/metrics | grep game_tick_duration
    sleep 300
done | tee soak_metrics.log

# 분석
grep "game_tick_duration_seconds{quantile=\"0.99\"}" soak_metrics.log | \
    awk '{if ($2 > 0.015) print "FAIL tick at", $1; else print "PASS"}'
```

---

## 10. 알려진 제약 & 향후 개선점

### 10.1 현재 제약

1. **히스토그램 메모리 누적**
   - 현재: 모든 값을 `std::vector`에 저장 → 메모리 무한 증가
   - 개선: 주기적으로 백분위 계산 후 clear, 또는 reservoir sampling

2. **단일 서버 메트릭만 지원**
   - 분산 서버 환경에서는 각 인스턴스 메트릭을 별도로 수집
   - 개선: Prometheus federation 또는 Pushgateway

3. **알람 노이즈**
   - 일시적 스파이크에도 알람 발생 가능
   - 개선: `for: 5m` 같은 지속 시간 조건 추가

### 10.2 최적화 기회

1. **메트릭 aggregation**
   - 서버 내부에서 1분 단위 aggregation 후 전송 → Prometheus 부하 감소

2. **커스텀 대시보드**
   - 각 프로젝트별로 핵심 메트릭만 표시 (불필요한 패널 제거)

3. **자동 SLO 검증**
   - Prometheus Alertmanager로 SLO 위반 시 자동 알람

---

## 11. v1.3와의 연결

v1.2에서 확립된 것:
- Prometheus 기반 메트릭 수집 인프라
- Grafana 대시보드 및 알람
- loadgen 부하 테스트 도구
- 재현 가능한 성능 벤치마크

v1.3에서 추가될 것:
- **Match/Room 서버 분리 메트릭**: 매치메이커 큐 크기, 룸 배정 지연
- **Redis 모니터링**: 세션 수, 체크포인트 크기, Redis 지연
- **재접속 메트릭**: 재접속 성공률, 체크포인트 복구 시간

---

## 12. 체크리스트 (v1.2 완료 기준)

- [ ] `PrometheusExporter` 클래스 구현
- [ ] HTTP /metrics 엔드포인트 동작 확인
- [ ] 모든 핵심 메트릭 (game, network, sync, state) 수집 확인
- [ ] Grafana 대시보드 생성 및 PromQL 쿼리 검증
- [ ] 알람 규칙 설정 및 테스트 (의도적으로 SLO 위반 유도)
- [ ] `loadgen` 도구 구현 및 CSV 출력
- [ ] 50/100/200 클라이언트 부하 테스트 실행
- [ ] Soak 테스트 (2시간) 통과
- [ ] 성능 회귀 방지 CI 스크립트 작성
- [ ] Docker Compose로 Prometheus/Grafana 로컬 환경 구축
- [ ] 문서화: 메트릭 정의, 대시보드 사용법, 부하 테스트 가이드
