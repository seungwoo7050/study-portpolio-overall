# 문서 1. 전체 아키텍처 & 로드맵 개요

## 1. 이 문서의 역할

이 문서는 **“전체 그림”만 보여주는 인덱스 문서**다.

* 대상: C로 서버/네이티브 개발은 해봤지만, JS/웹 스택은 처음인 개발자
* 목표:

  * React / Node / FFmpeg / (선택) C++ 애드온이 **어떤 구조로 연결되는지** 한 번에 이해
  * 어떤 순서(Stage)로 문서 2, 3, 4를 보면 되는지 파악
  * 각 Stage에서 **무엇을 만들고, 통과 기준이 뭔지** 명확히 정리

세부 문법, 코드, 설정은 각각:

* **문서 2**: C 개발자를 위한 JS/TS + Node 기본기
* **문서 3**: React + 프론트엔드 ↔ 백엔드 연동 실전
* **문서 4**: C++ / FFmpeg C API / 네이티브 애드온 (선택, 고급편)

에서 다룬다. 이 문서는 그 위에 얹는 “지도”라고 생각하면 된다.

---

## 2. 최종 목표: 어떤 기능을 만들 것인가

최종적으로 목표하는 기능은 단순하다:

> **브라우저에서 영상을 올리면, 서버가 FFmpeg로 처리해서 결과(클립, 썸네일, 메타데이터)를 돌려주고, 브라우저에서 바로 확인할 수 있는 시스템**

구체적으로:

1. **React 프론트엔드**

   * 파일 업로드 UI
   * 업로드 진행/결과 상태 표시
   * 결과 영상/썸네일/타임라인 등을 `<video>`, `<canvas>`로 표시

2. **Node.js 백엔드 (Express)**

   * 업로드된 파일을 **스트림으로 디스크에 저장**
   * FFmpeg을 CLI(child_process) 또는 (선택) C++ 애드온으로 호출
   * 처리 결과(파일 경로, 메타데이터)를 JSON으로 반환
   * 필요 시 결과 파일을 HTTP로 스트리밍

3. **FFmpeg**

   * CLI 방식: `ffmpeg -i input.mp4 -t 5 output.mp4` 같은 기본 명령
   * (선택) C++ + FFmpeg C API:

     * 더 세밀한 메타데이터/프레임 처리
     * Node 네이티브 애드온으로 노출할 수 있는 형태

**이 전체 플로우를 Stage 1 → 2 → 3으로 쪼개서 올라간다.**

---

## 3. 전체 아키텍처 한 번에 보기

### 3.1 논리적 구성도

```text
[React (TypeScript)]
  - 업로드 화면
  - 상태 관리 (idle/loading/done/error)
  - <video>, <canvas> 렌더링
          │  HTTP (JSON, 파일 업로드)
          ▼
[Node.js (Express, TypeScript)]
  - REST API (/upload, /videos/:id, /trim, /thumbnail)
  - 파일 I/O (스트림)
  - FFmpeg 호출 (child_process.spawn)
  - (선택) C++ 애드온 호출
          │  프로세스/함수 호출
          ▼
[FFmpeg]
  - CLI: 자르기, 인코딩, 썸네일 생성
  - (선택) C++ 라이브러리: 메타데이터, 프레임 단위 처리
```

관점 정리:

* **React**: UI + 사용자 입력. C세계로 치면 “프론트엔드 전용 클라이언트 프로그램”.
* **Node**: HTTP 서버 + I/O 오케스트레이션. C에서 만들던 서버 프로세스 역할.
* **FFmpeg / C++**: 무거운 영상 처리 로직. 기존 C 지식을 그대로 활용하는 영역.

---

### 3.2 요청–응답 시퀀스 (대표 시나리오)

예시 시나리오: **브라우저에서 영상 업로드 → 5초 클립 생성 → 결과 재생**

```text
1. 사용자가 브라우저에서 영상 파일 선택
2. React가 /api/upload 로 multipart/form-data 또는 스트림 업로드 요청
3. Node(Express)가 요청을 스트림으로 받아 디스크에 파일 저장
4. 저장 완료 후, Node가:
   - (1) FFmpeg CLI를 child_process.spawn으로 실행하거나
   - (2) C++ 애드온을 호출해 잘라낸 클립을 생성
5. FFmpeg/C++ 코드가 output 클립 생성 후 종료/리턴
6. Node가 DB 또는 간단한 메타데이터 저장(예: JSON 파일 or 메모리)
7. Node가 React에 "업로드 + 처리 완료" JSON 응답 (영상 ID, 클립 경로 등)
8. React가 해당 ID/URL로 /api/videos/:id or /static/... 에서 영상 가져와 재생
```

이 “한 줄 시나리오”를 위해 필요한 지식들을 Stage로 쪼갠 게 뒤에 나오는 로드맵이다.

---

## 4. Stage별 로드맵 개요

Stage는 “기술 이름” 기준이 아니라 **“검증 가능한 기능 단위”** 기준으로 나눈다.

* **Stage 1**: HTTP + JSON 위주의 얕은 연동
* **Stage 2**: 파일 I/O + FFmpeg CLI 연동
* **Stage 3**: C++/FFmpeg C API + 네이티브 애드온 (선택)

각 Stage마다:

* 필요 기술
* 만들어야 할 최소 기능
* 통과 체크리스트

를 명확하게 정의한다.

---

## 5. Stage 1 – JS/TS + Node + React 기본 통신

### 5.1 Stage 1의 목표

* JS/TS 기초 문법 + 비동기 패턴을 이해하고,
* Node + Express로 **간단한 REST API**를 만들 수 있고,
* React에서 이 API를 호출해서 **화면에 표시할 수 있는 수준**.

이 Stage에서는 **파일 업로드/FFmpeg는 아직 안 건드린다.**
목표는 “HTTP + JSON 통신 구조에 적응하는 것”.

### 5.2 다루는 기술

* JavaScript 기본

  * `let`/`const`, 함수, 화살표 함수
  * 객체/배열, 모듈(import/export)
  * `Promise`, `async/await`
  * `==` vs `===`, truthy/falsy, `this` 등 C와 다른 부분
* TypeScript 기본

  * 타입 주석, 함수 타입
  * `interface`, `type`, 유니온 타입
  * `any`를 피하는 패턴
* Node.js + Express

  * npm, package.json, ESM 기반 import
  * 간단한 REST API (`GET /ping`, `POST /echo`)
  * 기본 에러 핸들링 미들웨어
* React 기초

  * 함수형 컴포넌트 + JSX
  * props, `useState`, `useEffect`
  * 간단한 이벤트 핸들링 (버튼 클릭 → 상태 갱신)
  * React에서 fetch/axios로 백엔드 호출

### 5.3 이 Stage에서 완성해야 할 기능

최소 기능:

1. **백엔드**

   * `GET /ping` → `"pong"`
   * `POST /echo` → 받은 JSON 그대로 반환

2. **프론트엔드**

   * 텍스트 입력 + 버튼 하나 있는 단순 화면
   * 버튼 클릭 시 `/echo`로 JSON POST
   * 응답 JSON을 화면에 출력

### 5.4 통과 체크리스트

아래 항목에 “예”라고 말할 수 있으면 Stage 1 통과로 본다.

* [ ] TypeScript로 간단한 함수/인터페이스/유니온 타입을 만들고 컴파일 에러를 스스로 해결할 수 있다.
* [ ] Node + Express로 `/ping`, `/echo` 같은 REST 엔드포인트를 직접 만들고, curl/Postman으로 테스트할 수 있다.
* [ ] React에서 `useState`, `useEffect`를 이용해 상태를 관리하고, 버튼 클릭 같은 이벤트로 상태를 갱신할 수 있다.
* [ ] React에서 백엔드의 `/ping` 혹은 `/echo`를 호출해 응답을 화면에 표시하는 간단한 페이지를 만들 수 있다.
* [ ] 비동기 코드에서 `async/await`와 `try/catch`를 사용해서 에러를 처리할 수 있다.

Stage 1이 끝나면 **“파일이 아니라 JSON만 다루는 간단한 클라이언트–서버 시스템”을 혼자 만들 수 있는 상태**가 된다.

---

## 6. Stage 2 – 파일 I/O, FFmpeg CLI 연동

### 6.1 Stage 2의 목표

* Node 스트림을 이용해 **대용량 파일을 안전하게 업로드/저장**할 수 있고,
* FFmpeg CLI를 `child_process.spawn`으로 호출해서 **영상 자르기/썸네일 생성** 같은 작업을 자동화할 수 있으며,
* React에서 **파일 업로드 → 처리 결과 조회 → 결과 재생/표시**까지 end-to-end로 경험하는 것.

이 Stage까지가 사실상 “실무에서 바로 써먹을 수 있는 수준”이다.
Stage 3는 여기서 더 내려가고 싶을 때만 선택.

### 6.2 다루는 기술

* Node 파일 I/O, 스트림

  * `fs.createReadStream`, `fs.createWriteStream`
  * `req`/`res` 스트림을 파일에 pipe
  * 업로드 완료/에러 이벤트 처리
* 파일 업로드 API

  * Express에서 업로드 요청 처리
  * 단일/다중 파일, 임시 경로 관리
  * 용량 제한, 에러 처리(최소한의 수준)
* FFmpeg CLI + `child_process.spawn`

  * ffmpeg 실행, 인자 구성
  * stderr 로그 읽기, 종료 코드 체크
  * 자르기(`-t`), 썸네일(`-ss`, `-vframes`) 같은 간단 명령
* React에서 파일 업로드 + 결과 렌더링

  * `<input type="file">`, `<form>` 없이 fetch/axios로 직접 업로드
  * 업로드 상태 관리 (`idle` / `uploading` / `processing` / `done` / `error`)
  * 업로드 완료 후, 서버가 생성한 클립/썸네일 URL을 받아 `<video>` 또는 `<img>`로 표시

### 6.3 이 Stage에서 완성해야 할 기능

대표 시나리오 하나를 확실히 끝까지 구현하는 게 좋다.

**권장 시나리오**

1. React에서 영상 파일 선택 + 업로드 버튼 클릭

2. Node `/api/upload`가 스트림으로 파일 저장

3. 저장이 끝나면 Node가 FFmpeg CLI를 호출해서:

   * 5초 클립 또는 썸네일 1장 생성

4. 처리 완료 후 Node가 JSON으로 응답:

   ```json
   {
     "videoId": "abc123",
     "clipUrl": "/videos/abc123/clip.mp4",
     "thumbnailUrl": "/videos/abc123/thumbnail.jpg"
   }
   ```

5. React는 응답을 받아:

   * 썸네일을 `<img>`로 표시
   * 클립을 `<video>`로 재생

### 6.4 통과 체크리스트

* [ ] Node에서 업로드된 파일을 스트림으로 받아 디스크에 저장하는 코드를 직접 작성할 수 있다.
* [ ] 수백 MB짜리 영상 업로드 시에도 서버 메모리가 터지지 않고, 프로세스가 안정적으로 유지되는 것을 확인했다.
* [ ] Node에서 FFmpeg CLI를 `child_process.spawn`으로 실행하고, 종료 코드 0/비0을 구분해 성공/실패를 처리할 수 있다.
* [ ] React에서 파일 업로드 UI를 구현하고, 업로드/처리 진행 상태를 화면에 표시할 수 있다.
* [ ] 업로드한 영상에서 생성된 클립/썸네일을 브라우저에서 바로 재생/표시할 수 있다.

여기까지 구현하면, **실질적인 “동영상 처리 웹 서비스의 최소 골격”이 완성된 상태**다.

---

## 7. Stage 3 – C++ / FFmpeg C API / 네이티브 애드온 (선택)

### 7.1 Stage 3의 목표

이 Stage는 **필수 아님**이다. 정말로 “FFmpeg C API까지 써서 세밀한 처리/최적화를 하고 싶다”는 경우에만 들어간다.

목표는:

* C++의 RAII, 스마트 포인터를 이용해 FFmpeg C API를 안전하게 래핑하고,
* 필요한 경우 Node 네이티브 애드온으로 JS에서 호출 가능한 형태로 노출하는 것.

### 7.2 다루는 기술

* 현대 C++ 기초 (C 대비)

  * RAII, 스마트 포인터(`std::unique_ptr`, `std::shared_ptr`)
  * `std::string`, `std::vector` 등 STL 컨테이너
  * 예외 기반 에러 처리 (`throw` / `try-catch`)
* FFmpeg C API

  * `AVFormatContext`, `AVCodecContext`, `AVPacket`, `AVFrame` 기본 흐름
  * 파일 열기, 스트림 탐색, 디코더 초기화
  * 메타데이터/프레임 일부 읽기
* CMake 기반 빌드

  * FFmpeg 라이브러리 링크
  * Debug/Release 빌드 구성
* (선택) Node 네이티브 애드온

  * N-API 또는 관련 래퍼를 사용해 C++ 함수를 JS 함수처럼 노출
  * JS ↔ C++ 타입 변환, 에러 전달

### 7.3 이 Stage에서 완성해야 할 기능 (예시)

간단 예시 목표:

1. C++ 코드로 `getVideoInfo(path)` 구현:

   * width, height, duration, frame rate 등 반환
2. 이 함수를 Node에서 사용할 수 있도록:

   * (A) C++ 바이너리를 별도 CLI로 만들고, Node에서 `child_process.spawn`으로 호출
   * (B) 또는 네이티브 애드온으로 묶어 JS에서 직접 함수처럼 호출

현실적으로는 (A) 방식만으로도 충분한 경우가 많고, (B)는 진짜 필요할 때만 간다.

### 7.4 통과 체크리스트

* [ ] C++에서 FFmpeg C API를 사용해 영상의 기본 메타데이터(해상도, 길이 등)를 읽어오는 코드를 직접 작성하고 빌드/실행했다.
* [ ] CMake를 사용해 C++ 프로젝트를 빌드할 수 있고, FFmpeg 라이브러리를 링크하는 과정을 이해했다.
* [ ] Node에서 해당 C++ 코드를 (CLI 또는 애드온 형태로) 호출해, JS 코드에서 메타데이터를 받는 데 성공했다.
* [ ] 에러 발생 시 리소스 누수 없이 종료되도록 RAII/스마트 포인터를 적절히 사용했다.

---

## 8. 정리: 학습 순서 요약

추천 순서는 아래와 같다.

1. **문서 1 (지금 이 문서)**

   * 전체 구조/Stage/목표 확인

2. **문서 2 – C 개발자를 위한 JS/TS + Node 기본기**

   * Stage 1 내용을 채우는 문서
   * JS/TS 문법 + Node/Express + 간단 REST API까지

3. **문서 3 – React + 프론트엔드 ↔ 백엔드 연동 실전**

   * Stage 1의 React 부분 + Stage 2의 업로드/결과 표시까지 연결
   * end-to-end 업로드/재생 기능 완성

4. **문서 4 – C++ / FFmpeg C API / 네이티브 애드온 (선택)**

   * Stage 3에 해당
   * 진짜 C++ 레벨 최적화/특화 처리가 필요할 때만 들어감

이 문서는 여기까지.
다음 단계로는 **문서 2**에서 Stage 1 내용을 실제 코드/예제로 채우면 된다.
