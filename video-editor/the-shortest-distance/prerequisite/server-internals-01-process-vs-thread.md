# 🔥 서버 동작 이해 1편 – 프로세스와 스레드

서버 코드 이해하려면 제일 먼저 “프로세스”랑 “스레드”부터 정리해야 함.
이게 안 잡혀 있으면, 멀티프로세스/멀티스레드/비동기 서버 구조 설명이 전부 흐려짐.

---

## 1. 프로세스 – 실행의 기본 단위

**프로세스 = 실행 중인 프로그램 1개**라고 보면 됨.

### 1-1) 특징

1. **독립된 메모리 공간**

   * 코드, 데이터, 힙, 스택 전부 프로세스마다 따로 가짐.
   * A 프로세스에서 쓴 포인터 값 그대로 B 프로세스에 넘겨도 **의미 없음**.
     메모리 공간 자체가 다르기 때문.

2. **서로 격리됨**

   * 한 프로세스가 터져도(세그폴트 등) 다른 프로세스 메모리는 그대로.
   * OS 입장에선 “고객” 하나 죽었을 뿐, 나머지 고객은 영향 없음.

3. **통신하려면 별도 수단 필요**

   * 같은 프로세스끼리는 변수 공유 가능하지만,
   * 다른 프로세스끼리는 **IPC(파이프, 소켓, 공유 메모리 등)** 필요.

### 1-2) 서버에서 프로세스를 어떻게 씀?

대표 패턴 몇 개만 보면 됨.

* **프리포크(Pre-fork) 서버**

  * 메인 프로세스가 미리 워커 프로세스 여러 개 띄움.
  * 각 워커가 `accept()`해서 요청 처리.
  * 예: 옛날 Apache MPM prefork 같은 구조.

* **마스터–워커 구조**

  * 마스터 프로세스: 설정 로드, 포트 바인딩, 워커 관리.
  * 워커 프로세스: 실제 요청 처리.
  * 워커 죽으면 마스터가 새로 띄움.

장점:

* 한 워커가 메모리 뻑나도 전체 서버 안 죽음.
* CPU 코어 여러 개를 자연스럽게 활용 가능.

단점:

* 프로세스끼리 메모리 공유 안 되니, 공용 상태 공유가 귀찮아짐(IPC 필요).
* 프로세스 수가 많아지면 컨텍스트 스위칭 비용도 증가.

---

## 2. 스레드 – 프로세스 안에서의 실행 단위

**스레드 = 프로세스 안에서 돌아가는 작은 실행 흐름**.

하나의 프로세스 안에 스레드 여러 개 둘 수 있음.

### 2-1) 특징

1. **같은 프로세스 메모리를 공유**

   * 코드, 전역 변수, 힙 메모리는 **모든 스레드가 같이 봄**.
   * 각 스레드마다 따로 있는 건 **스택** 정도.

   예:

   ```text
   프로세스 A 메모리
   - 전역 변수 g_count
   - 힙에 올라간 객체들

   스레드 1, 2, 3 전부 g_count, 힙 객체에 접근 가능
   ```

2. **컨텍스트 스위칭 비용이 프로세스보다 싸다**

   * 같은 주소 공간을 공유하니 문맥 전환 비용이 상대적으로 적음.
   * 그래서 “동일 프로세스 내 병렬 작업”에는 스레드가 적합.

3. **하나 죽으면 같이 위험해질 수 있음**

   * 프로세스 안 스레드 하나가 메모리 터트리면,
     보통 **프로세스 전체가 죽음** → 모든 스레드 날아감.

### 2-2) 레이스 컨디션과 락

여기서 문제 시작.

**레이스 컨디션(race condition)**
여러 스레드가 **공유 데이터에 동시에 접근**해서
읽기/쓰기 순서에 따라 결과가 달라지는 상황.

예시:

```c
// 전역 변수
int count = 0;

// 여러 스레드가 동시에 실행
void handler() {
    count = count + 1;
}
```

CPU가 실제로는 다음처럼 실행한다고 치면:

1. 스레드 A: `count` 읽기 → 0
2. 스레드 B: `count` 읽기 → 0
3. 스레드 A: 0 + 1 계산 → 1 저장
4. 스레드 B: 0 + 1 계산 → 1 저장

요청 두 번 처리했는데 `count == 1` 됨.
논리상 기대값은 2여야 하는데 틀어짐.

그래서 **락(lock)** 이 필요함.

* `mutex` 같은 걸로 공유 데이터 접근 구간을 감싸서

  * 한 번에 한 스레드만 들어오게 막음.
* 대신 락 사용이 늘어나면

  * 병렬성이 떨어지고, 데드락(deadlock) 리스크도 생김.

스레드 기반 서버 설계할 때 항상 나오는 질문:

* "이 데이터는 스레드 간 공유해도 되는가?"
* "공유하면 락으로 감쌀 건가, 아니면 구조를 바꿔서 공유 자체를 줄일 건가?"

---

## 3. 프로세스 vs 스레드 – 서버 관점에서 비교

### 3-1) 메모리 관점

* **프로세스**

  * 완전 분리된 메모리 공간.
  * 안전하지만 공유 비용이 큼(IPC 필요).

* **스레드**

  * 메모리 대부분 공유.
  * 공유 비용 적지만, 레이스 컨디션/락 문제 필수로 따라옴.

### 3-2) 안정성 관점

* **프로세스 기반**

  * 워커 프로세스 하나 죽음 → 해당 프로세스만 영향.
  * 마스터가 새 워커 띄우면 복구 가능.
  * 격리가 잘 돼 있으니, 장애 범위가 상대적으로 제한적.

* **스레드 기반**

  * 한 스레드가 메모리 뻑내면 → 프로세스 전체 죽음.
  * 서버 프로세스 자체가 죽을 수 있으니 영향 범위 큼.

### 3-3) 성능/자원 관점

* **프로세스**

  * 생성/삭제 비용, 컨텍스트 스위칭 비용이 더 큼.
  * 하지만 요즘 OS/하드웨어 성능 생각하면 “무조건 느리다” 수준은 아님.
  * 다만 수천~수만 단위로 띄우기엔 부담.

* **스레드**

  * 생성/삭제 상대적으로 가볍고, 컨텍스트 스위칭도 덜 비쌈.
  * 하지만 너무 많이 만들면 스레드 스케줄링/스택 메모리 때문에 또 터짐.
  * 그래서 “스레드 풀” 패턴을 많이 씀.

---

## 4. 실제 서버 구조에서 어떻게 쓰이는지

패턴만 간단히 정리.

1. **멀티프로세스 서버**

   * 마스터 1개 + 워커 프로세스 N개.
   * 각 워커는 싱글 스레드인 경우도 많음.
   * 장점: 프로세스 격리로 안정성 확보.
   * 단점: 공용 상태 공유 어렵고, 프로세스 수 많아지면 관리 부담.

2. **멀티스레드 서버**

   * 프로세스 1개 + 워커 스레드 N개.
   * 공용 캐시/커넥션 풀 등을 전역으로 공유.
   * 장점: 공유 메모리라 공용 리소스 관리 쉬움.
   * 단점: 락 설계 잘못하면 성능도, 안정성도 둘 다 망함.

3. **혼합형**

   * 멀티프로세스 + 각 프로세스 안에서 멀티스레드.
   * 예: 워커 프로세스 여러 개, 각 워커가 스레드 풀 보유.
   * 장애 격리 + 스레드 유연성 둘 다 노리는 구조.

---

## 5. 이 1편에서 챙겨야 할 포인트 정리

요약만 보면 됨.

1. **프로세스**

   * 서로 **메모리 완전 격리**.
   * 안전하지만, 공유/통신은 IPC 필요.

2. **스레드**

   * **같은 프로세스 메모리 공유**.
   * 레이스 컨디션 반드시 고려해야 하고, 그래서 **락**이 필요.

3. **서버 설계 관점**

   * 안정성 중시 → 멀티프로세스 쪽이 유리.
   * 메모리 공유/성능 중시 → 멀티스레드 유리하지만 락 설계가 핵심.
   * 실제로는 두 개 섞어서 쓰는 구조도 많음.

다음 편(2편)에서 나올 I/O 모델(블로킹/논블로킹, 동기/비동기, 멀티플렉싱)이
“프로세스/스레드를 얼마나 쓰고, 어떻게 줄일 수 있는지”랑 바로 연결됨.
지금 내용만 정확히 잡혀 있으면, 뒤에 나오는 이벤트 루프, epoll, async/await 같은 것들 이해할 때 훨씬 덜 꼬인다.